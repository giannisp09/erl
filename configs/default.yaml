# Default configuration for ERL framework

# Experience stream settings
experience:
  buffer_size: 1000000
  batch_size: 256
  n_step: 3
  gamma: 0.99
  prioritized_replay: true
  alpha: 0.6
  beta: 0.4
  beta_anneal: 0.001

# Model settings
models:
  world_model:
    hidden_size: 512
    num_layers: 3
    dropout: 0.1
    learning_rate: 1e-4
  policy:
    hidden_size: 512
    num_layers: 2
    dropout: 0.1
    learning_rate: 3e-4

# RL algorithm settings
rl:
  ppo:
    clip_ratio: 0.2
    target_kl: 0.01
    value_coef: 0.5
    entropy_coef: 0.01
    max_grad_norm: 0.5
  curiosity:
    beta: 0.2
    learning_rate: 1e-4

# Planning settings
planning:
  horizon: 10
  num_simulations: 100
  exploration_constant: 1.0
  temperature: 1.0

# Training settings
training:
  num_epochs: 1000
  steps_per_epoch: 1000
  eval_interval: 10
  save_interval: 50
  log_interval: 10

# Logging settings
logging:
  wandb:
    project: "erl"
    entity: null
    tags: []
  tensorboard: true
  console: true 